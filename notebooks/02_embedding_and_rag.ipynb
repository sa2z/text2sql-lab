{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. ì„ë² ë”©(Embedding)ê³¼ RAG\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œ ë‹¤ë£¨ëŠ” ë‚´ìš©:\n",
    "- í…ìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì„ë² ë”© ìƒì„±\n",
    "- pgvectorë¥¼ ì‚¬ìš©í•˜ì—¬ PostgreSQLì— ì„ë² ë”© ì €ì¥\n",
    "- ì‹œë§¨í‹± ê²€ìƒ‰(Semantic Search) ìˆ˜í–‰\n",
    "- ê°„ë‹¨í•œ RAG(ê²€ìƒ‰ ì¦ê°• ìƒì„±, Retrieval-Augmented Generation) ì‹œìŠ¤í…œ êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace')\n",
    "\n",
    "from src.utils.db_utils import DatabaseConnection\n",
    "from src.utils.embedding_utils import (\n",
    "    EmbeddingGenerator,\n",
    "    chunk_text,\n",
    "    store_document_with_embedding,\n",
    "    search_similar_documents\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” connection\n",
    "db = DatabaseConnection()\n",
    "\n",
    "# ì„ë² ë”© ìƒì„±ê¸° ì´ˆê¸°í™”\n",
    "embedder = EmbeddingGenerator()\n",
    "print(f\"âœ“ Using embedding model: {embedder.model_name}\")\n",
    "print(f\"âœ“ Embedding dimension: {embedder.embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì„ë² ë”© ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "test_texts = [\n",
    "    \"What is the total revenue from sales?\",\n",
    "    \"Show me all employees in the engineering department\",\n",
    "    \"List all active projects\"\n",
    "]\n",
    "\n",
    "embeddings = embedder.generate_embeddings(test_texts)\n",
    "print(f\"Generated {len(embeddings)} embeddings\")\n",
    "print(f\"Each embedding has {len(embeddings[0])} dimensions\")\n",
    "print(f\"\\nFirst embedding (first 10 values): {embeddings[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì‹œë§¨í‹± ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¿¼ë¦¬ ê°„ ìœ ì‚¬ë„ ë¹„êµ\n",
    "query1 = \"Show me the revenue data\"\n",
    "query2 = \"What is the total sales amount?\"\n",
    "query3 = \"List all employees\"\n",
    "\n",
    "emb1 = embedder.generate_embedding(query1)\n",
    "emb2 = embedder.generate_embedding(query2)\n",
    "emb3 = embedder.generate_embedding(query3)\n",
    "\n",
    "sim_1_2 = embedder.cosine_similarity(emb1, emb2)\n",
    "sim_1_3 = embedder.cosine_similarity(emb1, emb3)\n",
    "\n",
    "print(f\"Similarity between '{query1}' and '{query2}': {sim_1_2:.4f}\")\n",
    "print(f\"Similarity between '{query1}' and '{query3}': {sim_1_3:.4f}\")\n",
    "print(\"\\nğŸ’¡ Higher scores indicate more semantic similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ì„ë² ë”©ìœ¼ë¡œ ìš©ì–´ì§‘ ì—…ë°ì´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ë² ë”©ì´ ì—†ëŠ” ê¸°ì¡´ ìš©ì–´ì§‘ í•­ëª© ê°€ì ¸ì˜¤ê¸°\n",
    "query = \"SELECT * FROM lexicon WHERE embedding IS NULL\"\n",
    "lexicon_entries = db.execute_query(query)\n",
    "\n",
    "print(f\"Found {len(lexicon_entries)} lexicon entries without embeddings\")\n",
    "\n",
    "# ì„ë² ë”© ìƒì„± ë° ì—…ë°ì´íŠ¸\n",
    "for entry in lexicon_entries:\n",
    "    # ë” ë‚˜ì€ ì‹œë§¨í‹± í‘œí˜„ì„ ìœ„í•´ ìš©ì–´ì™€ ì •ì˜ ê²°í•©\n",
    "    text = f\"{entry['term']}: {entry['definition']}\"\n",
    "    embedding = embedder.generate_embedding(text)\n",
    "    \n",
    "    # ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸\n",
    "    update_query = \"UPDATE lexicon SET embedding = %s WHERE lexicon_id = %s\"\n",
    "    conn = db.get_connection()\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(update_query, (embedding, entry['lexicon_id']))\n",
    "        conn.commit()\n",
    "    finally:\n",
    "        conn.close()\n",
    "    \n",
    "    print(f\"âœ“ Updated embedding for: {entry['term']}\")\n",
    "\n",
    "print(\"\\nâœ“ All lexicon entries updated with embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì„ë² ë”©ìœ¼ë¡œ ë¬¸ì„œ ì—…ë°ì´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ë² ë”©ì´ ì—†ëŠ” ê¸°ì¡´ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°\n",
    "query = \"SELECT * FROM documents WHERE embedding IS NULL\"\n",
    "documents = db.execute_query(query)\n",
    "\n",
    "print(f\"Found {len(documents)} documents without embeddings\")\n",
    "\n",
    "# ì„ë² ë”© ìƒì„± ë° ì—…ë°ì´íŠ¸\n",
    "for doc in documents:\n",
    "    # ì„ë² ë”©ì„ ìœ„í•´ ì œëª©ê³¼ ë‚´ìš© ì‚¬ìš©\n",
    "    text = f\"{doc['title']}: {doc['content']}\"\n",
    "    embedding = embedder.generate_embedding(text)\n",
    "    \n",
    "    # ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸\n",
    "    update_query = \"UPDATE documents SET embedding = %s WHERE document_id = %s\"\n",
    "    conn = db.get_connection()\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(update_query, (embedding, doc['document_id']))\n",
    "        conn.commit()\n",
    "    finally:\n",
    "        conn.close()\n",
    "    \n",
    "    print(f\"âœ“ Updated embedding for: {doc['title']}\")\n",
    "\n",
    "print(\"\\nâœ“ All documents updated with embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì‹œë§¨í‹± ê²€ìƒ‰ - ìš©ì–´ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê´€ë ¨ ìš©ì–´ì§‘ í•­ëª© ê²€ìƒ‰\n",
    "search_query = \"How do I convert natural language to SQL?\"\n",
    "query_embedding = embedder.generate_embedding(search_query)\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT \n",
    "    term,\n",
    "    definition,\n",
    "    category,\n",
    "    1 - (embedding <=> %s::vector) as similarity\n",
    "FROM lexicon\n",
    "WHERE embedding IS NOT NULL\n",
    "ORDER BY embedding <=> %s::vector\n",
    "LIMIT 3\n",
    "\"\"\"\n",
    "\n",
    "results = db.execute_query(sql, (query_embedding, query_embedding))\n",
    "\n",
    "print(f\"Search query: '{search_query}'\")\n",
    "print(\"\\nTop 3 relevant lexicon entries:\\n\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. {result['term']} (similarity: {result['similarity']:.4f})\")\n",
    "    print(f\"   Category: {result['category']}\")\n",
    "    print(f\"   Definition: {result['definition'][:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ì‹œë§¨í‹± ê²€ìƒ‰ - ë¬¸ì„œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
    "search_query = \"How to implement RAG system?\"\n",
    "results = search_similar_documents(db, search_query, limit=3)\n",
    "\n",
    "print(f\"Search query: '{search_query}'\")\n",
    "print(\"\\nTop 3 relevant documents:\\n\")\n",
    "for i, (doc_id, title, content, similarity) in enumerate(results, 1):\n",
    "    print(f\"{i}. {title} (similarity: {similarity:.4f})\")\n",
    "    print(f\"   Content: {content[:150]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ì„ë² ë”©ê³¼ í•¨ê»˜ ìƒˆ ë¬¸ì„œ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìë™ ì„ë² ë”©ê³¼ í•¨ê»˜ ìƒˆ ë¬¸ì„œ ì¶”ê°€\n",
    "new_doc = {\n",
    "    'title': 'Text2SQL Implementation Tips',\n",
    "    'content': '''Key tips for implementing text2sql:\n",
    "    1. Always include database schema in your prompt\n",
    "    2. Use few-shot examples to improve accuracy\n",
    "    3. Validate generated SQL before execution\n",
    "    4. Handle errors gracefully\n",
    "    5. Log all queries for monitoring and improvement\n",
    "    6. Consider using semantic similarity for schema retrieval\n",
    "    7. Test with various natural language phrasings\n",
    "    ''',\n",
    "    'doc_type': 'Guide',\n",
    "    'metadata': {'category': 'text2sql', 'author': 'system'}\n",
    "}\n",
    "\n",
    "doc_id = store_document_with_embedding(\n",
    "    db,\n",
    "    title=new_doc['title'],\n",
    "    content=new_doc['content'],\n",
    "    doc_type=new_doc['doc_type'],\n",
    "    metadata=new_doc['metadata']\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Added new document with ID: {doc_id}\")\n",
    "print(f\"  Title: {new_doc['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ê°„ë‹¨í•œ RAG ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rag_context(query: str, max_docs: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Build RAG context by retrieving relevant documents\n",
    "    \"\"\"\n",
    "    # Search for relevant documents\n",
    "    results = search_similar_documents(db, query, limit=max_docs)\n",
    "    \n",
    "    # Build context string\n",
    "    context = \"Relevant Information:\\n\\n\"\n",
    "    for i, (doc_id, title, content, similarity) in enumerate(results, 1):\n",
    "        context += f\"{i}. {title}\\n{content}\\n\\n\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "# Test RAG context building\n",
    "user_query = \"What are best practices for text2sql?\"\n",
    "rag_context = build_rag_context(user_query)\n",
    "\n",
    "print(f\"User Query: {user_query}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RAG Context (to be used in LLM prompt):\")\n",
    "print(\"=\"*60)\n",
    "print(rag_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. í…ìŠ¤íŠ¸ ì²­í‚¹(Chunking) ì˜ˆì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸´ í…ìŠ¤íŠ¸ ì²­í‚¹ ì˜ˆì œ\n",
    "long_text = \"\"\"\n",
    "Text2SQL is a technology that converts natural language queries into SQL statements.\n",
    "It uses large language models to understand the user's intent and generate appropriate\n",
    "database queries. The process typically involves: 1) Understanding the database schema,\n",
    "2) Parsing the natural language query, 3) Mapping entities to database tables and columns,\n",
    "4) Generating the SQL query, and 5) Validating and executing the query.\n",
    "\n",
    "Best practices include providing clear schema information, using few-shot examples,\n",
    "implementing proper error handling, and logging all queries for monitoring. It's also\n",
    "important to validate generated SQL to prevent injection attacks and ensure query safety.\n",
    "\n",
    "RAG can enhance text2sql by retrieving relevant schema information and examples.\n",
    "This helps the model generate more accurate queries by providing additional context.\n",
    "\"\"\" * 3  # Repeat to make it longer\n",
    "\n",
    "chunks = chunk_text(long_text, chunk_size=200, overlap=50)\n",
    "\n",
    "print(f\"Original text length: {len(long_text)} characters\")\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "print(\"\\nChunks:\")\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    print(f\"\\nChunk {i} ({len(chunk)} chars):\")\n",
    "    print(chunk[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ìš”ì•½\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œ ë°°ìš´ ë‚´ìš©:\n",
    "- âœ“ Sentence Transformersë¥¼ ì‚¬ìš©í•œ ì„ë² ë”© ìƒì„± ë°©ë²•\n",
    "- âœ“ pgvectorë¥¼ ì‚¬ìš©í•˜ì—¬ PostgreSQLì— ì„ë² ë”©ì„ ì €ì¥í•˜ëŠ” ë°©ë²•\n",
    "- âœ“ ì‹œë§¨í‹± ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰ ë°©ë²•\n",
    "- âœ“ ê°„ë‹¨í•œ RAG ì‹œìŠ¤í…œ êµ¬ì¶• ë°©ë²•\n",
    "- âœ“ ì²˜ë¦¬ë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ ì²­í‚¹ ë°©ë²•\n",
    "\n",
    "ë‹¤ìŒ ë‹¨ê³„: `03_text2sql_basic.ipynb`ë¡œ ì´ë™í•˜ì—¬ Text2SQL ì‹¤ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}