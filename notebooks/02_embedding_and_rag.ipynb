{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Embedding and RAG\n",
    "\n",
    "This notebook covers:\n",
    "- Generating embeddings for text\n",
    "- Storing embeddings in PostgreSQL with pgvector\n",
    "- Performing semantic search\n",
    "- Building a simple RAG (Retrieval-Augmented Generation) system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace')\n",
    "\n",
    "from src.utils.db_utils import DatabaseConnection\n",
    "from src.utils.embedding_utils import (\n",
    "    EmbeddingGenerator,\n",
    "    chunk_text,\n",
    "    store_document_with_embedding,\n",
    "    search_similar_documents\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize database connection\n",
    "db = DatabaseConnection()\n",
    "\n",
    "# Initialize embedding generator\n",
    "embedder = EmbeddingGenerator()\n",
    "print(f\"âœ“ Using embedding model: {embedder.model_name}\")\n",
    "print(f\"âœ“ Embedding dimension: {embedder.embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test embedding generation\n",
    "test_texts = [\n",
    "    \"What is the total revenue from sales?\",\n",
    "    \"Show me all employees in the engineering department\",\n",
    "    \"List all active projects\"\n",
    "]\n",
    "\n",
    "embeddings = embedder.generate_embeddings(test_texts)\n",
    "print(f\"Generated {len(embeddings)} embeddings\")\n",
    "print(f\"Each embedding has {len(embeddings[0])} dimensions\")\n",
    "print(f\"\\nFirst embedding (first 10 values): {embeddings[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare similarity between queries\n",
    "query1 = \"Show me the revenue data\"\n",
    "query2 = \"What is the total sales amount?\"\n",
    "query3 = \"List all employees\"\n",
    "\n",
    "emb1 = embedder.generate_embedding(query1)\n",
    "emb2 = embedder.generate_embedding(query2)\n",
    "emb3 = embedder.generate_embedding(query3)\n",
    "\n",
    "sim_1_2 = embedder.cosine_similarity(emb1, emb2)\n",
    "sim_1_3 = embedder.cosine_similarity(emb1, emb3)\n",
    "\n",
    "print(f\"Similarity between '{query1}' and '{query2}': {sim_1_2:.4f}\")\n",
    "print(f\"Similarity between '{query1}' and '{query3}': {sim_1_3:.4f}\")\n",
    "print(\"\\nðŸ’¡ Higher scores indicate more semantic similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Update Lexicon with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get existing lexicon entries without embeddings\n",
    "query = \"SELECT * FROM lexicon WHERE embedding IS NULL\"\n",
    "lexicon_entries = db.execute_query(query)\n",
    "\n",
    "print(f\"Found {len(lexicon_entries)} lexicon entries without embeddings\")\n",
    "\n",
    "# Generate and update embeddings\n",
    "for entry in lexicon_entries:\n",
    "    # Combine term and definition for better semantic representation\n",
    "    text = f\"{entry['term']}: {entry['definition']}\"\n",
    "    embedding = embedder.generate_embedding(text)\n",
    "    \n",
    "    # Update database\n",
    "    update_query = \"UPDATE lexicon SET embedding = %s WHERE lexicon_id = %s\"\n",
    "    conn = db.get_connection()\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(update_query, (embedding, entry['lexicon_id']))\n",
    "        conn.commit()\n",
    "    finally:\n",
    "        conn.close()\n",
    "    \n",
    "    print(f\"âœ“ Updated embedding for: {entry['term']}\")\n",
    "\n",
    "print(\"\\nâœ“ All lexicon entries updated with embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Update Documents with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get existing documents without embeddings\n",
    "query = \"SELECT * FROM documents WHERE embedding IS NULL\"\n",
    "documents = db.execute_query(query)\n",
    "\n",
    "print(f\"Found {len(documents)} documents without embeddings\")\n",
    "\n",
    "# Generate and update embeddings\n",
    "for doc in documents:\n",
    "    # Use title and content for embedding\n",
    "    text = f\"{doc['title']}: {doc['content']}\"\n",
    "    embedding = embedder.generate_embedding(text)\n",
    "    \n",
    "    # Update database\n",
    "    update_query = \"UPDATE documents SET embedding = %s WHERE document_id = %s\"\n",
    "    conn = db.get_connection()\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(update_query, (embedding, doc['document_id']))\n",
    "        conn.commit()\n",
    "    finally:\n",
    "        conn.close()\n",
    "    \n",
    "    print(f\"âœ“ Updated embedding for: {doc['title']}\")\n",
    "\n",
    "print(\"\\nâœ“ All documents updated with embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Semantic Search - Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for relevant lexicon terms\n",
    "search_query = \"How do I convert natural language to SQL?\"\n",
    "query_embedding = embedder.generate_embedding(search_query)\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT \n",
    "    term,\n",
    "    definition,\n",
    "    category,\n",
    "    1 - (embedding <=> %s::vector) as similarity\n",
    "FROM lexicon\n",
    "WHERE embedding IS NOT NULL\n",
    "ORDER BY embedding <=> %s::vector\n",
    "LIMIT 3\n",
    "\"\"\"\n",
    "\n",
    "results = db.execute_query(sql, (query_embedding, query_embedding))\n",
    "\n",
    "print(f\"Search query: '{search_query}'\")\n",
    "print(\"\\nTop 3 relevant lexicon entries:\\n\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. {result['term']} (similarity: {result['similarity']:.4f})\")\n",
    "    print(f\"   Category: {result['category']}\")\n",
    "    print(f\"   Definition: {result['definition'][:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Semantic Search - Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for relevant documents using utility function\n",
    "search_query = \"How to implement RAG system?\"\n",
    "results = search_similar_documents(db, search_query, limit=3)\n",
    "\n",
    "print(f\"Search query: '{search_query}'\")\n",
    "print(\"\\nTop 3 relevant documents:\\n\")\n",
    "for i, (doc_id, title, content, similarity) in enumerate(results, 1):\n",
    "    print(f\"{i}. {title} (similarity: {similarity:.4f})\")\n",
    "    print(f\"   Content: {content[:150]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Add New Document with Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new document with automatic embedding\n",
    "new_doc = {\n",
    "    'title': 'Text2SQL Implementation Tips',\n",
    "    'content': '''Key tips for implementing text2sql:\n",
    "    1. Always include database schema in your prompt\n",
    "    2. Use few-shot examples to improve accuracy\n",
    "    3. Validate generated SQL before execution\n",
    "    4. Handle errors gracefully\n",
    "    5. Log all queries for monitoring and improvement\n",
    "    6. Consider using semantic similarity for schema retrieval\n",
    "    7. Test with various natural language phrasings\n",
    "    ''',\n",
    "    'doc_type': 'Guide',\n",
    "    'metadata': {'category': 'text2sql', 'author': 'system'}\n",
    "}\n",
    "\n",
    "doc_id = store_document_with_embedding(\n",
    "    db,\n",
    "    title=new_doc['title'],\n",
    "    content=new_doc['content'],\n",
    "    doc_type=new_doc['doc_type'],\n",
    "    metadata=new_doc['metadata']\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Added new document with ID: {doc_id}\")\n",
    "print(f\"  Title: {new_doc['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Build Simple RAG Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rag_context(query: str, max_docs: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Build RAG context by retrieving relevant documents\n",
    "    \"\"\"\n",
    "    # Search for relevant documents\n",
    "    results = search_similar_documents(db, query, limit=max_docs)\n",
    "    \n",
    "    # Build context string\n",
    "    context = \"Relevant Information:\\n\\n\"\n",
    "    for i, (doc_id, title, content, similarity) in enumerate(results, 1):\n",
    "        context += f\"{i}. {title}\\n{content}\\n\\n\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "# Test RAG context building\n",
    "user_query = \"What are best practices for text2sql?\"\n",
    "rag_context = build_rag_context(user_query)\n",
    "\n",
    "print(f\"User Query: {user_query}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RAG Context (to be used in LLM prompt):\")\n",
    "print(\"=\"*60)\n",
    "print(rag_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Text Chunking Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of chunking long text\n",
    "long_text = \"\"\"\n",
    "Text2SQL is a technology that converts natural language queries into SQL statements.\n",
    "It uses large language models to understand the user's intent and generate appropriate\n",
    "database queries. The process typically involves: 1) Understanding the database schema,\n",
    "2) Parsing the natural language query, 3) Mapping entities to database tables and columns,\n",
    "4) Generating the SQL query, and 5) Validating and executing the query.\n",
    "\n",
    "Best practices include providing clear schema information, using few-shot examples,\n",
    "implementing proper error handling, and logging all queries for monitoring. It's also\n",
    "important to validate generated SQL to prevent injection attacks and ensure query safety.\n",
    "\n",
    "RAG can enhance text2sql by retrieving relevant schema information and examples.\n",
    "This helps the model generate more accurate queries by providing additional context.\n",
    "\"\"\" * 3  # Repeat to make it longer\n",
    "\n",
    "chunks = chunk_text(long_text, chunk_size=200, overlap=50)\n",
    "\n",
    "print(f\"Original text length: {len(long_text)} characters\")\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "print(\"\\nChunks:\")\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    print(f\"\\nChunk {i} ({len(chunk)} chars):\")\n",
    "    print(chunk[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "- âœ“ How to generate embeddings using sentence transformers\n",
    "- âœ“ How to store embeddings in PostgreSQL with pgvector\n",
    "- âœ“ How to perform semantic similarity search\n",
    "- âœ“ How to build a simple RAG system\n",
    "- âœ“ How to chunk text for processing\n",
    "\n",
    "Next: Move to `03_text2sql_basic.ipynb` to start working with text2sql."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
